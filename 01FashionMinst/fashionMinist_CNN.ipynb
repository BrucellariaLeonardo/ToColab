{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiper params\n",
    "batchSize = 64\n",
    "lr = 0.01\n",
    "epochs = 2\n",
    "divice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descargando dataset\n",
    "\n",
    "trainSet = datasets.FashionMNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
    "testSet = datasets.FashionMNIST(root='./', train=False, transform=transforms.ToTensor(), download=True)\n",
    "# data loader\n",
    "trainLoader = DataLoader(trainSet, batch_size=batchSize, shuffle=True,)\n",
    "testLoader = DataLoader(testSet, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquitectura \n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels= 12, kernel_size= 3,stride=1, padding=1) # 1 input channel, 3 output channels, 1x1 kernel size img out 28*28\n",
    "        self.bn1 = nn.BatchNorm2d(12)       # img out 28*28\n",
    "        self.cnn2 = nn.Conv2d(12,24,3,2,1)   # img out 14*14\n",
    "        self.bn2 = nn.BatchNorm2d(24)       # img out 14*14\n",
    "        self.cnn3 = nn.Conv2d(24,48,3,2,1)   # img out 7*7\n",
    "        self.bn3 = nn.BatchNorm2d(48)       # img out 7*7\n",
    "        self.flat = nn.Flatten()           # img out 7*7\n",
    "        self.fc1 = nn.Linear(48*7*7,10)     # img out 7*7\n",
    "    def forward(self,x):\n",
    "        # Definicion de la forma en la que se ejecuta la arquitectura de la red\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn1(self.cnn1(x)))\n",
    "        #print(f\"k= 1 s= 1, shape ={x.shape}\")\n",
    "        x = F.relu(self.bn2(self.cnn2(x)))\n",
    "        #print(f\"k= 2 s= 2, shape ={x.shape}\")\n",
    "        x = F.relu(self.bn3(self.cnn3(x)))\n",
    "        #print(f\"k= 2 s= 2, shape ={x.shape}\")\n",
    "        x = self.flat(x)\n",
    "        #print(f\"k= 2 s= 2, shape ={x.shape}\")\n",
    "        x = self.fc1(x)\n",
    "        #print(f\"k= 2 s= 2, shape ={x.shape}\")\n",
    "        return x\n",
    "    def trainer(self, model, data, lossFunction,optimizer, epochs = 2):\n",
    "        # Funcion que controla el ciclo de ejecucion durante el entrenamiento de la red\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            print(epoch)\n",
    "            for (x,y) in data:\n",
    "                # llamdos al forward\n",
    "                pred = model(x)\n",
    "                loss= lossFunction(pred,y)\n",
    "                #calgulo de los gradientes mediante backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                #actualizar parametros\n",
    "                optimizer.step()\n",
    "        return\n",
    "    def check_acuracy(self,model,dataLoader):\n",
    "        # Funcion que calcula la performance de la red\n",
    "        model.eval() #ponemos el modelo en modo evaluacion, de modo que no altera los parametros\n",
    "        corrects = 0\n",
    "        samples = 0\n",
    "\n",
    "        with torch.no_grad(): #desactivamos los gradientes\n",
    "            for x,y in dataLoader:\n",
    "                pred = model(x)\n",
    "                pred = pred.argmax(dim=1)\n",
    "                corrects += (pred == y).sum()\n",
    "                samples += x.shape[0]\n",
    "        print('Accuracy: %.2f' % (corrects/samples))\n",
    "        model.train() #reactivamos el entrenamiento\n",
    "        return corrects/samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1753, -0.3921,  0.3442,  0.5994,  0.0499, -0.2464, -0.2992,  0.2590,\n",
       "          0.3350,  0.5482]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ejemplo para probar que la arquitecutra funciona\n",
    "example = torch.randn(1,1,28,28)\n",
    "\n",
    "exampleModel = NN()\n",
    "exampleModel(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando modelo\n",
    "\n",
    "model = NN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Accuracy: 0.92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9228)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testeo para buscar lr \n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
    "model.trainer(model, trainLoader, loss, optimizer)\n",
    "model.check_acuracy(model,trainLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr  acuracy\n",
    "\n",
    "0.01    0.92\n",
    "\n",
    "0.005   0.92\n",
    "\n",
    "0.001   0.94\n",
    "\n",
    "0.0005  0.92\n",
    "\n",
    "0.0001  0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Entrenando modelo\n",
    "model = NN()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for lr,epochs in [(0.01,2),(0.001,5),(0.0001,2)]:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "    model.trainer(model, trainLoader, loss, optimizer, epochs)\n",
    "model.check_acuracy(model, trainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar modelo\n",
    "torch.save(model.state_dict(), 'model_CNN_0.0.2.5.2_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-shirt/top\n",
      "T-shirt/top\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c35968eaa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usando el modelo\n",
    "img = 85\n",
    "print(trainSet.classes[model(testSet[img][0].unsqueeze(0)).argmax()] )\n",
    "print(trainSet.classes[testSet[img][1]])\n",
    "plt.imshow(testSet[img][0].reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Acuracy final\n",
    "model.check_acuracy(model, testLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados del entrenamiento\n",
    "10 epochs = 91%\n",
    "\n",
    "15 epochs = "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9be826744cc5714b462ad0c8de88bfa6f016a48973c6317b9546595d1685cabb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
