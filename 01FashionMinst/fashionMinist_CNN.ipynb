{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiper params\n",
    "batchSize = 64\n",
    "lr = 0.01\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descargando dataset\n",
    "\n",
    "trainSet = datasets.FashionMNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
    "testSet = datasets.FashionMNIST(root='./', train=False, transform=transforms.ToTensor(), download=True)\n",
    "# data loader\n",
    "trainLoader = DataLoader(trainSet, batch_size=batchSize, shuffle=True)\n",
    "testLoader = DataLoader(testSet, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquitectura \n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels= 12, kernel_size= 3,stride=1, padding=1) # 1 input channel, 3 output channels, 1x1 kernel size img out 28*28\n",
    "        self.bn1 = nn.BatchNorm2d(12)       # img out 28*28\n",
    "        self.cnn2 = nn.Conv2d(12,24,3,2,1)   # img out 14*14\n",
    "        self.bn2 = nn.BatchNorm2d(24)       # img out 14*14\n",
    "        self.cnn3 = nn.Conv2d(24,48,3,2,1)   # img out 7*7\n",
    "        self.bn3 = nn.BatchNorm2d(48)       # img out 7*7\n",
    "        self.flat = nn.Flatten()           # img out 7*7\n",
    "        self.fc1 = nn.Linear(48*7*7,10)     # img out 7*7\n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn1(self.cnn1(x)))\n",
    "        #print(f\"k= 1 s= 1, shape ={x.shape}\")\n",
    "        x = F.relu(self.bn2(self.cnn2(x)))\n",
    "        #print(f\"k= 2 s= 2, shape ={x.shape}\")\n",
    "        x = F.relu(self.bn3(self.cnn3(x)))\n",
    "        #print(f\"k= 2 s= 2, shape ={x.shape}\")\n",
    "        x = self.flat(x)\n",
    "        #print(f\"k= 2 s= 2, shape ={x.shape}\")\n",
    "        x = self.fc1(x)\n",
    "        #print(f\"k= 2 s= 2, shape ={x.shape}\")\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5396, -0.0198,  0.1609, -0.8086,  0.5264,  0.5758,  0.2187,  0.2298,\n",
       "          0.6347,  0.6403]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ejemplo para probar que la arquitecutra funciona\n",
    "example = torch.randn(1,1,28,28)\n",
    "\n",
    "exampleModel = NN()\n",
    "exampleModel(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, lossFunction,optimizer, epochs = 1):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        for (x,y) in data:\n",
    "            #forward\n",
    "            pred = model(x)\n",
    "            loss= lossFunction(pred,y)\n",
    "            #backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #actualizar parametros\n",
    "            optimizer.step()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_acuracy(loader,model):\n",
    "    corrects = 0\n",
    "    samples = 0\n",
    "    model.eval() #ponemos el modelo en modo evaluacion, de modo que no altera los parametros\n",
    "\n",
    "    with torch.no_grad(): #desactivamos los gradientes\n",
    "        for x,y in loader:\n",
    "            pred = model(x)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            corrects += (pred == y).sum()\n",
    "            samples += x.shape[0]\n",
    "    print('Accuracy: %.2f' % (corrects/samples))\n",
    "    model.train() #reactivamos el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando modelo\n",
    "\n",
    "model = NN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "#Testeo para buscar lr \n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
    "train(model, trainLoader, loss, optimizer, 2)\n",
    "check_acuracy(trainLoader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr  acuracy\n",
    "\n",
    "0.01    0.92\n",
    "\n",
    "0.005   0.92\n",
    "\n",
    "0.001   0.94\n",
    "\n",
    "0.0005  0.92\n",
    "\n",
    "0.0001  0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leona\\Documents\\ToColab\\01FashionMinst\\fashionMinist_CNN.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000010?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m lr,epochs \u001b[39min\u001b[39;00m [(\u001b[39m0.01\u001b[39m,\u001b[39m2\u001b[39m),(\u001b[39m0.001\u001b[39m,\u001b[39m5\u001b[39m),(\u001b[39m0.0001\u001b[39m,\u001b[39m2\u001b[39m)]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000010?line=4'>5</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m lr)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000010?line=5'>6</a>\u001b[0m     train(model, trainLoader, loss, optimizer, epochs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000010?line=6'>7</a>\u001b[0m check_acuracy(trainLoader, model)\n",
      "\u001b[1;32mc:\\Users\\leona\\Documents\\ToColab\\01FashionMinst\\fashionMinist_CNN.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data, lossFunction, optimizer, epochs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000005?line=8'>9</a>\u001b[0m \u001b[39m#backward\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000005?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000005?line=10'>11</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000005?line=11'>12</a>\u001b[0m \u001b[39m#actualizar parametros\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000005?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/leona/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entrenando modelo\n",
    "model = NN()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for lr,epochs in [(0.01,2),(0.001,5),(0.0001,2)]:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
    "    train(model, trainLoader, loss, optimizer, epochs)\n",
    "check_acuracy(trainLoader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leona\\Documents\\UNRN\\Artificial integence\\Tutoriales\\Yt\\fashionMinist_CNN_06_2.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/UNRN/Artificial%20integence/Tutoriales/Yt/fashionMinist_CNN_06_2.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39m#guardar modelo\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/UNRN/Artificial%20integence/Tutoriales/Yt/fashionMinist_CNN_06_2.ipynb#ch0000012?line=1'>2</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39mmodel_CNN_10epochs_0.06.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#guardar modelo\n",
    "torch.save(model.state_dict(), 'model_CNN_10epochs_0.06.2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandal\n",
      "Sandal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f70249a5f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usando el modelo\n",
    "img = 8\n",
    "print(trainSet.classes[model(testSet[img][0].unsqueeze(0)).argmax()] )\n",
    "print(trainSet.classes[testSet[img][1]])\n",
    "plt.imshow(testSet[img][0].reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_acuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leona\\Documents\\ToColab\\01FashionMinst\\fashionMinist_CNN.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39m# Acuracy final\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/leona/Documents/ToColab/01FashionMinst/fashionMinist_CNN.ipynb#ch0000020?line=1'>2</a>\u001b[0m check_acuracy(testLoader, model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_acuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# Acuracy final\n",
    "check_acuracy(testLoader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados del entrenamiento\n",
    "10 epochs = 91%\n",
    "\n",
    "15 epochs = "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9be826744cc5714b462ad0c8de88bfa6f016a48973c6317b9546595d1685cabb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
